{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2cP1GtC--adG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X_U4l6B-qzJ",
        "outputId": "0f2cf7f2-38b1-41f3-b21e-59b4824d212d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocess\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/web3gle/Last Task/customer_churn (1).csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop('customerID', axis=1)\n",
        "\n",
        "# Convert TotalCharges to numeric (coerce errors to NaN)\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Handle missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "df['gender'] = df['gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
        "\n",
        "# One-Hot Encode categorical features\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Scaling the numerical features\n",
        "cols_to_scale = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "scaler = MinMaxScaler()\n",
        "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df.drop('Churn_Yes', axis=1)\n",
        "y = df['Churn_Yes']\n"
      ],
      "metadata": {
        "id": "jhZzsVg9-iEL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Model Evaluation"
      ],
      "metadata": {
        "id": "O7eR_fjX-8H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Support Vector Machine\": SVC(probability=True, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "# Function to evaluate models\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    return model\n",
        "\n",
        "# Evaluate each model on imbalanced data\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEvaluating {name} on imbalanced data:\")\n",
        "    evaluate_model(model, X_train, X_test, y_train, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYjetOFE-kMM",
        "outputId": "005154d8-65f4-4ac8-cb2b-51aada669b4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Logistic Regression on imbalanced data:\n",
            "Accuracy: 0.8045\n",
            "AUC-ROC: 0.8348\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.85      0.89      0.87      1033\n",
            "        True       0.65      0.57      0.61       374\n",
            "\n",
            "    accuracy                           0.80      1407\n",
            "   macro avg       0.75      0.73      0.74      1407\n",
            "weighted avg       0.80      0.80      0.80      1407\n",
            "\n",
            "\n",
            "Evaluating K-Nearest Neighbors on imbalanced data:\n",
            "Accuracy: 0.7512\n",
            "AUC-ROC: 0.7668\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.84      0.82      0.83      1033\n",
            "        True       0.53      0.57      0.55       374\n",
            "\n",
            "    accuracy                           0.75      1407\n",
            "   macro avg       0.68      0.69      0.69      1407\n",
            "weighted avg       0.76      0.75      0.75      1407\n",
            "\n",
            "\n",
            "Evaluating Random Forest on imbalanced data:\n",
            "Accuracy: 0.7903\n",
            "AUC-ROC: 0.8171\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.83      0.89      0.86      1033\n",
            "        True       0.63      0.51      0.56       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.73      0.70      0.71      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n",
            "\n",
            "Evaluating Support Vector Machine on imbalanced data:\n",
            "Accuracy: 0.7896\n",
            "AUC-ROC: 0.7942\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.83      0.89      0.86      1033\n",
            "        True       0.63      0.51      0.56       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.73      0.70      0.71      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n",
            "\n",
            "Evaluating XGBoost on imbalanced data:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [15:36:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7669\n",
            "AUC-ROC: 0.8142\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.83      0.86      0.84      1033\n",
            "        True       0.57      0.52      0.54       374\n",
            "\n",
            "    accuracy                           0.77      1407\n",
            "   macro avg       0.70      0.69      0.69      1407\n",
            "weighted avg       0.76      0.77      0.76      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Class Imbalance Techniques"
      ],
      "metadata": {
        "id": "Ekcz0Sp9_DFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Random Over-Sampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "# Evaluate each model with Random Over-Sampling\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEvaluating {name} after Random Over-Sampling:\")\n",
        "    evaluate_model(model, X_ros, X_test, y_ros, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ_mRNEV_Aez",
        "outputId": "0ff5e473-a79a-4b7f-89e9-336dbe6fd7e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Logistic Regression after Random Over-Sampling:\n",
            "Accuracy: 0.7264\n",
            "AUC-ROC: 0.8346\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.70      0.79      1033\n",
            "        True       0.49      0.79      0.61       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.70      0.75      0.70      1407\n",
            "weighted avg       0.79      0.73      0.74      1407\n",
            "\n",
            "\n",
            "Evaluating K-Nearest Neighbors after Random Over-Sampling:\n",
            "Accuracy: 0.6851\n",
            "AUC-ROC: 0.7515\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.66      0.76      1033\n",
            "        True       0.45      0.75      0.56       374\n",
            "\n",
            "    accuracy                           0.69      1407\n",
            "   macro avg       0.66      0.71      0.66      1407\n",
            "weighted avg       0.76      0.69      0.70      1407\n",
            "\n",
            "\n",
            "Evaluating Random Forest after Random Over-Sampling:\n",
            "Accuracy: 0.7783\n",
            "AUC-ROC: 0.8161\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.85      0.85      0.85      1033\n",
            "        True       0.58      0.59      0.58       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.72      0.72      0.72      1407\n",
            "weighted avg       0.78      0.78      0.78      1407\n",
            "\n",
            "\n",
            "Evaluating Support Vector Machine after Random Over-Sampling:\n",
            "Accuracy: 0.7335\n",
            "AUC-ROC: 0.8029\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.72      0.80      1033\n",
            "        True       0.50      0.77      0.60       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.70      0.74      0.70      1407\n",
            "weighted avg       0.79      0.73      0.75      1407\n",
            "\n",
            "\n",
            "Evaluating XGBoost after Random Over-Sampling:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [15:38:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7498\n",
            "AUC-ROC: 0.8135\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.86      0.78      0.82      1033\n",
            "        True       0.52      0.66      0.58       374\n",
            "\n",
            "    accuracy                           0.75      1407\n",
            "   macro avg       0.69      0.72      0.70      1407\n",
            "weighted avg       0.77      0.75      0.76      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Evaluate each model with SMOTE\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEvaluating {name} after SMOTE:\")\n",
        "    evaluate_model(model, X_smote, X_test, y_smote, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbwkOHqm_H-l",
        "outputId": "5374f2b2-218b-4f27-91a5-eb8b0710de17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Logistic Regression after SMOTE:\n",
            "Accuracy: 0.7420\n",
            "AUC-ROC: 0.8276\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.89      0.74      0.81      1033\n",
            "        True       0.51      0.74      0.61       374\n",
            "\n",
            "    accuracy                           0.74      1407\n",
            "   macro avg       0.70      0.74      0.71      1407\n",
            "weighted avg       0.79      0.74      0.75      1407\n",
            "\n",
            "\n",
            "Evaluating K-Nearest Neighbors after SMOTE:\n",
            "Accuracy: 0.6979\n",
            "AUC-ROC: 0.7620\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.69      0.77      1033\n",
            "        True       0.46      0.73      0.56       374\n",
            "\n",
            "    accuracy                           0.70      1407\n",
            "   macro avg       0.67      0.71      0.67      1407\n",
            "weighted avg       0.76      0.70      0.71      1407\n",
            "\n",
            "\n",
            "Evaluating Random Forest after SMOTE:\n",
            "Accuracy: 0.7704\n",
            "AUC-ROC: 0.8116\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.86      0.82      0.84      1033\n",
            "        True       0.56      0.64      0.60       374\n",
            "\n",
            "    accuracy                           0.77      1407\n",
            "   macro avg       0.71      0.73      0.72      1407\n",
            "weighted avg       0.78      0.77      0.78      1407\n",
            "\n",
            "\n",
            "Evaluating Support Vector Machine after SMOTE:\n",
            "Accuracy: 0.7385\n",
            "AUC-ROC: 0.8064\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.74      0.81      1033\n",
            "        True       0.51      0.73      0.60       374\n",
            "\n",
            "    accuracy                           0.74      1407\n",
            "   macro avg       0.69      0.74      0.70      1407\n",
            "weighted avg       0.78      0.74      0.75      1407\n",
            "\n",
            "\n",
            "Evaluating XGBoost after SMOTE:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [15:38:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7655\n",
            "AUC-ROC: 0.8143\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      0.80      0.83      1033\n",
            "        True       0.55      0.66      0.60       374\n",
            "\n",
            "    accuracy                           0.77      1407\n",
            "   macro avg       0.71      0.73      0.72      1407\n",
            "weighted avg       0.78      0.77      0.77      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_with_class_weight(model, X_train, X_test, y_train, y_test):\n",
        "    if hasattr(model, 'class_weight'):  # Ensure the model supports class_weight\n",
        "        # Fit the model with class_weight set to 'balanced'\n",
        "        model.set_params(class_weight='balanced')\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_prob = model.predict_proba(X_test)[:, 1]\n",
        "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "        print(f\"AUC-ROC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    else:\n",
        "        print(f\"{model} does not support class_weight parameter.\")\n",
        "    return model\n",
        "\n",
        "# Evaluate each model with class weight adjustment\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEvaluating {name} with class weight adjustment:\")\n",
        "    evaluate_model_with_class_weight(model, X_train, X_test, y_train, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d0_73-v_NRo",
        "outputId": "1a12569d-43d0-4bd5-c8a2-4e62e107096e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Logistic Regression with class weight adjustment:\n",
            "Accuracy: 0.7271\n",
            "AUC-ROC: 0.8345\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.70      0.79      1033\n",
            "        True       0.49      0.79      0.61       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.70      0.75      0.70      1407\n",
            "weighted avg       0.79      0.73      0.74      1407\n",
            "\n",
            "\n",
            "Evaluating K-Nearest Neighbors with class weight adjustment:\n",
            "KNeighborsClassifier() does not support class_weight parameter.\n",
            "\n",
            "Evaluating Random Forest with class weight adjustment:\n",
            "Accuracy: 0.7875\n",
            "AUC-ROC: 0.8187\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.83      0.90      0.86      1033\n",
            "        True       0.63      0.48      0.54       374\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.73      0.69      0.70      1407\n",
            "weighted avg       0.77      0.79      0.78      1407\n",
            "\n",
            "\n",
            "Evaluating Support Vector Machine with class weight adjustment:\n",
            "Accuracy: 0.7249\n",
            "AUC-ROC: 0.8070\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.71      0.79      1033\n",
            "        True       0.49      0.78      0.60       374\n",
            "\n",
            "    accuracy                           0.72      1407\n",
            "   macro avg       0.69      0.74      0.70      1407\n",
            "weighted avg       0.79      0.72      0.74      1407\n",
            "\n",
            "\n",
            "Evaluating XGBoost with class weight adjustment:\n",
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric='logloss',\n",
            "              feature_types=None, gamma=None, grow_policy=None,\n",
            "              importance_type=None, interaction_constraints=None,\n",
            "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
            "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
            "              max_leaves=None, min_child_weight=None, missing=nan,\n",
            "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
            "              n_jobs=None, num_parallel_tree=None, random_state=42, ...) does not support class_weight parameter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "In this study, we evaluated five classification algorithms (Logistic Regression, K-Nearest Neighbors, Random Forest, Support Vector Machine, and XGBoost) on an imbalanced dataset. We applied different class imbalance (CI) techniques, including Random Over-Sampling, SMOTE, and class weight adjustments. The results demonstrated that CI techniques generally improved recall for the minority class but often led to a decrease in overall accuracy."
      ],
      "metadata": {
        "id": "FKM5gO5bAP-0"
      }
    }
  ]
}